# HierSpeech2: Hierarhical Variational Autoencoder is a Strong Zero-shot Unified Speech Synthesizer 
The official implementation of HierSpeech2 | [Paper]() | [Demo page]()

**Sang-Hoon Lee, Ha-Yeong Choi, Seong-Whan Lee<sup>*</sup>**

Department of Artificial Intelligence, Korea University, Seoul, Korea  
<sup>*</sup> Corresponding author

## Abstract


## Previous Works
- [1] HierSpeech: Bridging the Gap between Text and Speech by Hierarchical Variational Inference using Self-supervised Representations for Speech Synthesis
- [2] HierVST: HierVST: Hierarchical Adaptive Zero-shot Voice Style Transfer

This paper is an extenstion version of above papers.

## Updates
- ** 1 October, 2023**: Release H
## Todo
[ ] 

## Getting Started

### Pre-requisites

## Checkpoint
| Model |Dataset |Checkpoint|
|------|:---:|:---:|
| HierSpeech2 | LibriTTS (train-clean-360, train-clean-100) |-|
| HierSpeech2-Large  | LibriTTS (train-clean-360, train-clean-100)  |-|
| HierSpeech2-Large-Full  | LibriTTS (train-clean-360, train-clean-100, train-other-500, VCTK, CSS10, NIKL, Others)  |-|
## Reference
- VITS: https://github.com/jaywalnut310/vits
- UnivNET: https://github.com/mindslab-ai/univnet
- Wav2Vec 2.0: https://arxiv.org/abs/2006.11477
- XLS-R: https://huggingface.co/facebook/wav2vec2-xls-r-300m
- MMS:  
- BigVGAN: https://arxiv.org/abs/2206.04658
- NANSY: 
